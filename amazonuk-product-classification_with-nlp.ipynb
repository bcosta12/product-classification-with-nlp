{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon UK product classificatio with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data/raw\n",
    "!curl -o './data/raw/amazon_reviews_multilingual_UK_v1_00.tsv.gz' 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_UK_v1_00.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 unpack gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip './data/raw/amazon_reviews_multilingual_UK_v1_00.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 101882: expected 15 fields, saw 22\\nSkipping line 115512: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 328404: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1412642: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/raw/amazon_reviews_multilingual_UK_v1_00.tsv',  sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "df = df[['product_id', 'product_parent', 'product_title', 'product_category', 'review_body', 'review_headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B00MWK7BWG</td>\n",
       "      <td>307651059</td>\n",
       "      <td>My Favourite Faded Fantasy</td>\n",
       "      <td>Music</td>\n",
       "      <td>The best album ever!</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B006CHML4I</td>\n",
       "      <td>835010224</td>\n",
       "      <td>Seiko 5 Men's Automatic Watch with Black Dial ...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>What a great watch. Both watches and strap is ...</td>\n",
       "      <td>Great watch from casio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B00IIFCJX0</td>\n",
       "      <td>271687675</td>\n",
       "      <td>Dexter Season 8</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>love watching all the episodes of Dexter, when...</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B000W7JWUA</td>\n",
       "      <td>211383699</td>\n",
       "      <td>The Settlers of Catan Board Game - discontinue...</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Excellent game!!!</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B005JTAP4S</td>\n",
       "      <td>182965893</td>\n",
       "      <td>Peter: A Darkened Fairytale (Vol 1)</td>\n",
       "      <td>Digital_Ebook_Purchase</td>\n",
       "      <td>This cute, quick read is very different to say...</td>\n",
       "      <td>A twist on Tales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  product_parent  \\\n",
       "0  B00MWK7BWG       307651059   \n",
       "1  B006CHML4I       835010224   \n",
       "2  B00IIFCJX0       271687675   \n",
       "3  B000W7JWUA       211383699   \n",
       "4  B005JTAP4S       182965893   \n",
       "\n",
       "                                       product_title        product_category  \\\n",
       "0                         My Favourite Faded Fantasy                   Music   \n",
       "1  Seiko 5 Men's Automatic Watch with Black Dial ...                 Watches   \n",
       "2                                    Dexter Season 8  Digital_Video_Download   \n",
       "3  The Settlers of Catan Board Game - discontinue...                    Toys   \n",
       "4                Peter: A Darkened Fairytale (Vol 1)  Digital_Ebook_Purchase   \n",
       "\n",
       "                                         review_body          review_headline  \n",
       "0                               The best album ever!               Five Stars  \n",
       "1  What a great watch. Both watches and strap is ...  Great watch from casio.  \n",
       "2  love watching all the episodes of Dexter, when...                fantastic  \n",
       "3                                  Excellent game!!!               Five Stars  \n",
       "4  This cute, quick read is very different to say...         A twist on Tales  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_category\n",
       "Apparel                          2\n",
       "Automotive                     530\n",
       "Baby                          4328\n",
       "Beauty                           2\n",
       "Books                       257803\n",
       "Camera                        6427\n",
       "Digital_Ebook_Purchase      289112\n",
       "Digital_Music_Purchase       29264\n",
       "Digital_Video_Download       31422\n",
       "Electronics                   5846\n",
       "Health & Personal Care         246\n",
       "Home                          2690\n",
       "Home Entertainment             117\n",
       "Home Improvement               950\n",
       "Kitchen                         21\n",
       "Lawn and Garden                240\n",
       "Luggage                         10\n",
       "Mobile_Apps                 218031\n",
       "Music                       329865\n",
       "Musical Instruments           2832\n",
       "Office Products                984\n",
       "PC                           16258\n",
       "Personal_Care_Appliances       100\n",
       "Pet Products                    43\n",
       "Shoes                         1718\n",
       "Software                        77\n",
       "Sports                        2336\n",
       "Toys                         24496\n",
       "Video                         4580\n",
       "Video DVD                   463200\n",
       "Video Games                   3592\n",
       "Watches                       3101\n",
       "Wireless                      5593\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['product_category']].groupby(['product_category']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = train.product_category\n",
    "X_train = train[['product_title', 'review_body', 'review_headline']]\n",
    "\n",
    "y_test = test.product_category\n",
    "X_test = test[['product_title', 'review_body', 'review_headline']]\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "product_title_pipeline = Pipeline([\n",
    "    ('product_title', TextSelector(key='product_title')),\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "])\n",
    "\n",
    "\n",
    "review_body_pipeline = Pipeline([\n",
    "    ('review_body', TextSelector(key='review_body')),\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "])\n",
    "\n",
    "\n",
    "review_headline_pipeline = Pipeline([\n",
    "    ('product_title', TextSelector(key='review_headline')),\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    ('text', product_title_pipeline), \n",
    "    ('length', review_body_pipeline),\n",
    "    ('words', review_headline_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('product_title',\n",
       "                                                                  TextSelector(key='product_title')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=No...\n",
       "                                                                                  min_df=1,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               1),\n",
       "                                                                                  norm='l2',\n",
       "                                                                                  preprocessor=None,\n",
       "                                                                                  smooth_idf=True,\n",
       "                                                                                  stop_words='english',\n",
       "                                                                                  strip_accents=None,\n",
       "                                                                                  sublinear_tf=False,\n",
       "                                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                                  tokenizer=None,\n",
       "                                                                                  use_idf=True,\n",
       "                                                                                  vocabulary=None))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', MultinomialNB(fit_prior=False)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.16%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = pipeline.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('product_title',\n",
       "                                                                  TextSelector(key='product_title')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=No...\n",
       "                ('classifier',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter_no_change=5, random_state=42)),\n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.78%\n"
     ]
    }
   ],
   "source": [
    "predicted = pipeline2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refs\n",
    "- https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "- https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "- https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
